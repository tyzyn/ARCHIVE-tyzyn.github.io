<!DOCTYPE html>
<html lang="en">
<head>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@300&display=swap" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css2?family=Space+Mono&display=swap" rel="stylesheet">
	<title>Chris Tyson : Balls to the Connecting Wall</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="./theme/css/main.css" type="text/css" />
        <link href="./" type="application/atom+xml" rel="alternate" title="Chris Tyson ATOM Feed" />

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="./css/ie.css"/>
                <script src="./js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="./css/ie6.css"/><![endif]-->

</head>

<body>

  <nav class="navbar">
    <ul class="navbar-nav">
      <li class="logo">
	<a href="/" class="nav-link">
	<span class="link-text logo-text">Chris Tyson</span>
          <svg
            aria-hidden="true"
            focusable="false"
            data-prefix="fad"
            data-icon="angle-double-right"
            role="img"
            xmlns="http://www.w3.org/2000/svg"
            viewBox="0 0 448 512"
            class="svg-inline--fa fa-angle-double-right fa-w-14 fa-5x">
            <g class="fa-group">
              <path
                fill="currentColor"
                d="M224 273L88.37 409a23.78 23.78 0 0 1-33.8 0L32 386.36a23.94 23.94 0 0 1 0-33.89l96.13-96.37L32 159.73a23.94 23.94 0 0 1 0-33.89l22.44-22.79a23.78 23.78 0 0 1 33.8 0L223.88 239a23.94 23.94 0 0 1 .1 34z"
                class="fa-secondary"
              ></path>
              <path
                fill="currentColor"
                d="M415.89 273L280.34 409a23.77 23.77 0 0 1-33.79 0L224 386.26a23.94 23.94 0 0 1 0-33.89L320.11 256l-96-96.47a23.94 23.94 0 0 1 0-33.89l22.52-22.59a23.77 23.77 0 0 1 33.79 0L416 239a24 24 0 0 1-.11 34z"
                class="fa-primary"
              ></path>
            </g>
          </svg>
	</a>
      </li>

      <li class="nav-item">
        <a href="/about.html" class="nav-link">
          <svg aria-hidden="true"
               focusable="false"
               data-prefix="fas"
               data-icon="user-circle"
               class="svg-inline--fa fa-briefcase fa-w-16"
               role="img"
               xmlns="http://www.w3.org/2000/svg"
               viewBox="0 0 512 512">
            <g class="fa-group">
            <path fill="currentColor"
                  class="fa-primary"
                  d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 96c48.6 0 88 39.4 88 88s-39.4 88-88 88-88-39.4-88-88 39.4-88 88-88zm0 344c-58.7 0-111.3-26.6-146.5-68.2 18.8-35.4 55.6-59.8 98.5-59.8 2.4 0 4.8.4 7.1 1.1 13 4.2 26.6 6.9 40.9 6.9 14.3 0 28-2.7 40.9-6.9 2.3-.7 4.7-1.1 7.1-1.1 42.9 0 79.7 24.4 98.5 59.8C359.3 421.4 306.7 448 248 448z">
            </path>
            </g>
          </svg>
          <span class="link-text">About</span>
        </a>
      </li>

      <li class="nav-item">
        <a href="/blog.html" class="nav-link">
          <svg aria-hidden="true"
               focusable="false"
               data-prefix="fas"
               data-icon="pen-alt"
               class="svg-inline--fa fa-briefcase fa-w-16"
               role="img"
               xmlns="http://www.w3.org/2000/svg"
               viewBox="0 0 512 512">
            <g class="fa-group">
            <path fill="currentColor"
                  class="fa-primary"
                  d="M497.94 74.17l-60.11-60.11c-18.75-18.75-49.16-18.75-67.91 0l-56.55 56.55 128.02 128.02 56.55-56.55c18.75-18.75 18.75-49.15 0-67.91zm-246.8-20.53c-15.62-15.62-40.94-15.62-56.56 0L75.8 172.43c-6.25 6.25-6.25 16.38 0 22.62l22.63 22.63c6.25 6.25 16.38 6.25 22.63 0l101.82-101.82 22.63 22.62L93.95 290.03A327.038 327.038 0 0 0 .17 485.11l-.03.23c-1.7 15.28 11.21 28.2 26.49 26.51a327.02 327.02 0 0 0 195.34-93.8l196.79-196.79-82.77-82.77-84.85-84.85z">
            </path>
            </g>
          </svg>
          <span class="link-text">Blog</span>
        </a>
      </li> 

      <li class="nav-item">
        <a href="/projects.html" class="nav-link">
          <svg aria-hidden="true"
               focusable="false"
               data-prefix="fas"
               data-icon="code"
               class="svg-inline--fa fa-briefcase fa-w-16"
               role="img"
               xmlns="http://www.w3.org/2000/svg"
               viewBox="0 0 640 512">
            <g class="fa-group">
            <path fill="currentColor"
                  class="fa-primary"
                  d="M278.9 511.5l-61-17.7c-6.4-1.8-10-8.5-8.2-14.9L346.2 8.7c1.8-6.4 8.5-10 14.9-8.2l61 17.7c6.4 1.8 10 8.5 8.2 14.9L293.8 503.3c-1.9 6.4-8.5 10.1-14.9 8.2zm-114-112.2l43.5-46.4c4.6-4.9 4.3-12.7-.8-17.2L117 256l90.6-79.7c5.1-4.5 5.5-12.3.8-17.2l-43.5-46.4c-4.5-4.8-12.1-5.1-17-.5L3.8 247.2c-5.1 4.7-5.1 12.8 0 17.5l144.1 135.1c4.9 4.6 12.5 4.4 17-.5zm327.2.6l144.1-135.1c5.1-4.7 5.1-12.8 0-17.5L492.1 112.1c-4.8-4.5-12.4-4.3-17 .5L431.6 159c-4.6 4.9-4.3 12.7.8 17.2L523 256l-90.6 79.7c-5.1 4.5-5.5 12.3-.8 17.2l43.5 46.4c4.5 4.9 12.1 5.1 17 .6z">
            </path>
            </g>
          </svg>
	  <span class="link-text">Projects</span>
        </a>
      </li>

      <li class="nav-item">
        <a href="/documents/cv.pdf" class="nav-link">
	  <svg aria-hidden="true"
	       focusable="false"
	       data-prefix="fas"
	       data-icon="briefcase"
	       class="svg-inline--fa fa-briefcase fa-w-16"
	       role="img"
	       xmlns="http://www.w3.org/2000/svg"
	       viewBox="0 0 512 512">
	    <g class="fa-group">
	    <path fill="currentColor"
		  class="fa-primary"
	          d="M320 336c0 8.84-7.16 16-16 16h-96c-8.84 0-16-7.16-16-16v-48H0v144c0 25.6 22.4 48 48 48h416c25.6 0 48-22.4 48-48V288H320v48zm144-208h-80V80c0-25.6-22.4-48-48-48H176c-25.6 0-48 22.4-48 48v48H48c-25.6 0-48 22.4-48 48v80h512v-80c0-25.6-22.4-48-48-48zm-144 0H192V96h128v32z">
	    </path>
	    </g>
	  </svg>
          <span class="link-text">CV</span>
        </a>
      </li>

    </ul>
  </nav>

  <div id="wrap" style="width:850px">
    <div id="container" style="width:560px">

      <div class="entry">
        
<header>
<h1><a href="." id="site-title">  </a>         <a href="./balls-to-the-connecting-wall.html" id="page-title">Balls to the Connecting Wall</a></h1>
<time datetime="2019-01-08T00:00:00+00:00">Tue 08 January 2019</time></header>
<article>
    <p>I'm a huge fan of quiz shows, and in particular the BBC show Only Connect. I've always wanted to see if I could hold my own against the teams at the "Connecting Wall", and have since found an online game here inspired by the show, however I wanted to try this out with real walls from the show.</p>
<p>~image1~</p>
<p>Inspired another blog post which scraped YouTube video subtitles for University Challenge questions, I decided that it probably wouldn't be too difficult to put together an automated way of grabbing walls from Only Connect videos.</p>
<p>However I was soon left scratching my head. Ideally I wanted to extract frames from the YouTube video, at the exact moment the solved connecting wall was in frame. In the recent series the graphics haven't changed, and so the positioning of it remains stationary - however the time at which it appears is completely variable.</p>
<p>I realised that Victoria Coren Mitchell says certain things when the wall has been solved/the time limit is up: "you've solved the wall", or "what about the green group" or "let's resolve the wall" being some of them.</p>
<p>So if I had a way to find out when these things were said, the search space of finding the frames that contain the wall would be tightened - and this is where subtitles come in!</p>
<p>With some help from some code I found on Github it turns out the manually written / auto-generated subtitle files are rather easy to download from YouTube videos in very few lines of Python.</p>
<p>And with some processing you can get to a list of pairs like this:</p>
<div class="highlight"><pre><span></span><code><span class="p">(</span><span class="s2">&quot;&#39;00:22:11.970 --&gt; 00:22:11.980&quot;</span><span class="p">,</span> <span class="s2">&quot;and a half minutes solve the water wall&#39;&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Then it's a matter of finding the pairs that have some meaningful information in. I found that the following searching method produced some good timestamps, although it's fairly naive.</p>
<div class="highlight"><pre><span></span><code><span class="c1">#phrase check for subs that would suggest a solved wall</span>
<span class="k">def</span> <span class="nf">solved_wall</span><span class="p">(</span><span class="n">sub</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="n">sub</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">,</span> <span class="s2">&quot;resolve&quot;</span><span class="p">])</span>

<span class="c1">#timestamps at which the connecting wall may be on screen</span>
<span class="n">wall_times</span> <span class="o">=</span> <span class="p">[</span><span class="n">sub</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">sub</span> <span class="ow">in</span> <span class="n">subs</span> <span class="k">if</span> <span class="n">solved_wall</span><span class="p">(</span><span class="n">sub</span><span class="p">)]</span>
</code></pre></div>

<p>After this these timestamps can be turned into real numbers, and then plugged into code that can grab frames from a YouTube video at that time. This is also a fairly trivial task that can be solved using the Python libraries pafy and cv2, instead of having to download the entire video.</p>
<div class="highlight"><pre><span></span><code><span class="c1">#load the youtube video into a video capture</span>
<span class="n">vpafy</span> <span class="o">=</span> <span class="n">pafy</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">play</span> <span class="o">=</span> <span class="n">vpafy</span><span class="o">.</span><span class="n">getbestvideo</span><span class="p">(</span><span class="n">preftype</span><span class="o">=</span><span class="s2">&quot;mp4&quot;</span><span class="p">)</span>
<span class="n">vidcap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="n">play</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>

<span class="c1">#iterate through timestamps in order, if you find a wall add to list</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">timestamps</span><span class="p">):</span>
    <span class="c1">#grab image at timestamp t</span>
    <span class="n">vidcap</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_POS_MSEC</span><span class="p">,</span> <span class="p">(</span><span class="n">t</span><span class="o">*</span><span class="mi">1000</span><span class="p">))</span>
    <span class="n">success</span><span class="p">,</span> <span class="n">image</span> <span class="o">=</span> <span class="n">vidcap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</code></pre></div>

<p>After this we crop to the dimensions of a wall in the shot, and then we (maybe) have a cropped wall image.</p>
<p>~image2~</p>
<p>But what makes a wall a wall?</p>
<p>At first I was wondering if I'd need some sort of complex computer vision algorithm to determine if the cropped shot is a wall, but it can be done in a far easier way.</p>
<p>The colouring of a solved wall as shown here is another constant of the show, so if we take the average colour of the first column, we can test the average colour of that area of found shots againsts it. Using euclidean distance between our average_wall_colour and average_found_colour and a threshold value, we can come up with an estimation of whether a frame contains a wall or not.</p>
<p>And that's more or less it!</p>
<p>After this I extracted the first and last known wall images (hoping that they were the solved lion and water walls) and from here all that needs doing is using OCR to extract the text from walls. I like pytesseract although this can be a little temperamental sometimes. To combat this the images were preprocessed to be black text on a white background (using PIL) which made OCR accuracy far higher.</p>
<p>Now let's resolve the wall!</p>
<div class="highlight"><pre><span></span><code>Cover, Gully, Point, Long on
Ditch, Gutter, Culvert, Channel
Catcher, Slip, Pat, Boy
Trench, Butch, Creek, Banish
</code></pre></div>
</article>
      </div>
    </div>
  </div>

</body>
</html>